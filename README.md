<style>
r { color: Red }
o { color: Orange }
g { color: Green }
c { color: Cyan }
blue { color: Blue }
customb { color: #006699 }
</style>

# Welcome!
I am a third-year Ph.D. student in Computer Science at the University of Illinois at Urbana-Champaign advised by Prof. Julia Hockenmaier. My research primarily centers around model architecture engineering, including: 
- Creating and analyzing novel deep learning model architectures
- Analyzing and enhancing the Mixture-of-Experts framework
- Designing user-controllable deep learning models
- Developing novel (model compression, machine unlearning, etc.) techniques.

## Education
- University of Illinois at Urbana-Champaign &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Aug 2021 ~ Current
  - Ph.D. student in Computer Science								       		
- Seoul National University  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Mar 2013 ~ Feb 2021
  - B.S. in Electrical and Computer Enginering

## Fellowships
- University of Illinois at Urbana-Champaign
  - CS Ph.D. Fellowship &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sep 2023 - May 2024

## Publications
<!--1. Prompting for Model Compression: A Novel Transformer-based Model Compression Technique via Prompt Learning and Parameter Sharing<br><customb>In preparation (estimated date: 2.15.2024)</customb><br>**Ikhyun Cho** and Julia Hockenmaier-->
1. MoE-ABSC: A Dependency-guided Mixture-of-Experts Framework for Aspect-based Sentiment Analysis<br><customb>In preparation (estimated date: 2.15.2024)</customb><br>**Ikhyun Cho** and Julia Hockenmaier
2. ViTMUL: An Analysis on Recent Vision Transformer Unlearning Methods <br><customb>In preparation (estimated date: 1.25.2024)</customb><br>**Ikhyun Cho**, Changyeon Park, and Julia Hockenmaier
3. Collaborative Unlearning: Towards Robust Machine Unlearning via Mixture-of-Experts with a Freeze-and-Shuffle Constraint<br><customb>In preparation (estimated date: 1.25.2024)</customb><br>**Ikhyun Cho** and Julia Hockenmaier
4. Attack and Reset for Unlearning: Exploiting Adversarial Noise toward Machine Unlearning through Parameter Re-initialization<br><customb>Under review at IJCAI 2024</customb><br>Yoonhwa Jung, **Ikhyun Cho**, Shun-Hsiang Hsu, and Julia Hockenmaier<br><a href="https://arxiv.org/abs/2401.08998" style="color: #006699; text-decoration: underline;text-decoration-style: dotted;">[PDF]</a>
5. VisualSiteDiary: A Detector-Free Vision-Language Transformer Model for Captioning Photologs for Daily Construction Reporting and Image Retrievals<br><customb>Under review at Elsevier: Automation in Construction</customb><br>Yoonhwa Jung, **Ikhyun Cho**, and Julia Hockenmaier
6. SIR-ABSC: Incorporating Syntax into RoBERTa-based Sentiment Analysis Models with a Special Aggregator Token<br><customb>EMNLP 2023 Findings</customb><br>**Ikhyun Cho**, Yoonhwa Jung, and Julia Hockenmaier<br><a href="https://aclanthology.org/2023.findings-emnlp.572/" style="color: #006699; text-decoration: underline;text-decoration-style: dotted;">[PDF]</a>
