<style>
r { color: Red }
o { color: Orange }
g { color: Green }
c { color: Cyan }
blue { color: Blue }
customb { color: #006699 }
</style>

# Welcome!
I am a fourth-year Ph.D. student in Computer Science at the University of Illinois at Urbana-Champaign advised by Prof. Julia Hockenmaier. My research primarily centers around: 
- Creating and analyzing novel deep learning model architectures
- Improving the in-context learning framework using large language models (LLMs)
- Enhancing spatial reasoning capabilities of LLMs

## Education
- University of Illinois at Urbana-Champaign &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Aug 2021 ~ Current
  - Ph.D. student in Computer Science								       		
- Seoul National University  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Mar 2013 ~ Feb 2021
  - B.S. in Electrical and Computer Enginering

## Fellowships
- University of Illinois at Urbana-Champaign
  - CS Ph.D. Fellowship &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sep 2023 - May 2024

## Publications
1. Anonymous <br><customb>Under review at ARR 2024 August</customb><br>**Ikhyun Cho**, Changyeon Park, and Julia Hockenmaier
2. Tutor-ICL: Guiding Large Language Models for Improved In-Context Learning Performance <br><customb>EMNLP 2024 Findings</customb><br>**Ikhyun Cho**, Gaeul Kwon, and Julia Hockenmaier
3. SIR-ABSC: Incorporating Syntax into RoBERTa-based Sentiment Analysis Models with a Special Aggregator Token<br><a href="https://aclanthology.org/2023.findings-emnlp.572/" style="color: #006699;">EMNLP 2023 Findings</a><br>**Ikhyun Cho**, Yoonhwa Jung, and Julia Hockenmaier
4. VisualSiteDiary: A Detector-Free Vision-Language Transformer Model for Captioning Photologs for Daily Construction Reporting and Image Retrievals<br><a href="https://www.sciencedirect.com/science/article/pii/S092658052400219X" style="color: #006699;">Elsevier: Automation in Construction</a><br>Yoonhwa Jung, **Ikhyun Cho**, and Julia Hockenmaier
5. Duplicate-and-Share: A Novel Approach to Efficient Vision Transformer Unlearning<br><customb>Under review at AAAI 2025</customb><br>**Ikhyun Cho**, Changyeon Park, and Julia Hockenmaier
6. Pea-KD: Parameter-efficient and accurate Knowledge Distillation on BERT<br><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0263592" style="color: #006699;">PLOS ONE 2022</a><br>**Ikhyun Cho** and U Kang
7. SensiMix: Sensitivity-Aware 8-bit index & 1-bit value mixed precision quantization for BERT compression<br><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0265621" style="color: #006699;">PLOS ONE 2022</a><br>Tairen Piao, **Ikhyun Cho**, and U Kang
